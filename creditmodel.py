# -*- coding: utf-8 -*-
"""creditmodel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gvOeee8ZvvFeGVbX56mUA3ga6mTATqYD
"""

# importer les packages
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
import pickle
from sklearn.model_selection import GridSearchCV
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc, confusion_matrix
import matplotlib.pyplot as plt

#lire la base de données
df=pd.read_csv('/content/train_u6lujuX_CVtuZ9i.csv')
df



# voir les valeurs manquantes
#data cleaning
df.info()



# Renseigner les valeurs manquantes
cat_data=[]
num_data=[]
for i,c in enumerate(df.dtypes):
  if c==object:
    cat_data.append(df.iloc[:,i])
  else:
    num_data.append(df.iloc[:,i])
cat_data=pd.DataFrame(cat_data).transpose()
num_data=pd.DataFrame(num_data).transpose()

#Pour les variables catégoriques on va remplacer les valeurs manquantes par les valeurs qui se repetent le plus
cat_data=cat_data.apply(lambda x:x.fillna(x.value_counts().index[0]))
cat_data.isnull().sum().any()

#Pour les variables numériques on va remplacer les valeurs manquantes par la valeur précedente de la meme colonne
num_data.fillna(method='bfill',inplace=True)
num_data.isnull().sum().any()

# Tranformer la colonne target
target_value={'Y':1,'N':0}
target=cat_data['Loan_Status']
cat_data.drop('Loan_Status',axis=1,inplace=True)
target=target.map(target_value)
target

# Remplacer les valeurs catégoriques par des valeurs numérique 0,1,2...
le=LabelEncoder()
for i in cat_data:
  cat_data[i]=le.fit_transform(cat_data[i])
cat_data

# Supprimer loan_id
cat_data.drop('Loan_ID',axis=1,inplace=True)

# Concatener cat_Data et num_data et spécifier la colonne target
X=pd.concat([cat_data,num_data],axis=1)
y=target



#Analyse Exploratoire
target.value_counts()

df=pd.concat([cat_data,num_data,target],axis=1)
# la base de données utilisée pour EDA

plt.figure(figsize=(8, 6))

# Tracer le graphique de comptage des valeurs de la variable cible avec deux couleurs
sns.countplot(x=target)

# Calculer les pourcentages des crédits accordés et non accordés
yes=target.value_counts()[0]/len(target)
no=target.value_counts()[1]/len(target)

# Afficher les pourcentages sous forme de texte
plt.text(0, target.value_counts()[0], f' crédits accordés: {yes:.2f}', ha='center')
plt.text(1, target.value_counts()[1], f' crédits non accordés: {no:.2f}', ha='center')

# Ajouter un titre au graphique
plt.title('Répartition des crédits accordés et non accordés')


print(f'le pourcentage des crédits accordés est: {yes}')
print(f'le pourcentage des crédits non accordés est: {no}')
# Afficher le graphique
plt.show()

"""plt.figure(figsize=(8,6))
sns.countplot(target)
yes=target.value_counts()[0]/len(target)
no=target.value_counts()[1]/len(target)
print(f'le pourcentage des crédits accordés est: {yes}')
print(f'le pourcentage des crédits non accordés est: {no}')
"""

# Credit history
grid=sns.FacetGrid(df,col='Loan_Status',aspect=1.6)
grid.map(sns.countplot,'Credit_History')

# Sexe
grid=sns.FacetGrid(df,col='Loan_Status',aspect=1.6)
grid.map(sns.countplot,'Gender')

# Married
grid=sns.FacetGrid(df,col='Loan_Status',aspect=1.6)
grid.map(sns.countplot,'Married')

# Education
grid=sns.FacetGrid(df,col='Loan_Status',aspect=1.6)
grid.map(sns.countplot,'Education')

# revenu du demandeur
plt.scatter(df['ApplicantIncome'],df['Loan_Status'])

# revenu du conjoint
plt.scatter(df['CoapplicantIncome'],df['Loan_Status'])

df.groupby('Loan_Status').median()

# Diviser la base de données en une base de données test et d'entrainement
sss=StratifiedShuffleSplit(n_splits=1,test_size=0.2,random_state=42)
for train,test in sss.split(X,y):
  X_train,X_test=X.iloc[train],X.iloc[test]
  y_train,y_test=y.iloc[train],y.iloc[test]

print('X_train taille: ', X_train.shape)
print('X_test taille: ', X_test.shape)
print('y_train taille: ', y_train.shape)
print('y_test taille: ', y_test.shape)

# On va appliquer tois algorithmes Logisitic Regression, KNN, DecisionTree
models={
    'SVM': SVC(kernel='linear', random_state=42),
    'LogisticRegression':LogisticRegression(random_state=42),
    'KNeighborsClassifier':KNeighborsClassifier(),
    'DecisionTreeClassifier':DecisionTreeClassifier(max_depth=1,random_state=42)

}

# La fonction de précision
def accu(y_true,y_pred,retu=False):
  acc=accuracy_score(y_true,y_pred)
  if retu:
    return acc
  else:
    print(f'la precision du modèle est: {acc}')

#c'est la fonction d'application des modèles
def train_test_eval(models,X_train,y_train,X_test,y_test):
  for name,model in models.items():
    print(name,':')
    model.fit(X_train,y_train)
    accu(y_test,model.predict(X_test))
    print('-'*30)

train_test_eval(models,X_train,y_train,X_test,y_test)

#hyperparametre
param_grid_logistic = {'C': [0.1, 1, 10]}


# Initialiser les modèles avec leurs paramètres par défaut
models = {

    'LogisticRegression': LogisticRegression(random_state=42)

}

# Fonction d'application des modèles avec recherche sur grille
def train_test_eval_grid(models, param_grids, X_train, y_train, X_test, y_test):
    for name, model in models.items():
        grid_search = GridSearchCV(estimator=model, param_grid=param_grids[name], cv=5)
        grid_search.fit(X_train, y_train)
        best_model = grid_search.best_estimator_
        print(f"Meilleurs paramètres pour {name}: {grid_search.best_params_}")
        accu(y_test, best_model.predict(X_test))
        print('-' * 30)

# Exécution de la recherche sur grille pour chaque modèle
param_grids = {

    'LogisticRegression': param_grid_logistic
}

train_test_eval_grid(models, param_grids, X_train, y_train, X_test, y_test)

param_grid_knn = {'n_neighbors': [3, 5, 7, 9]}


# Initialiser les modèles avec leurs paramètres par défaut
models = {

    'KNeighborsClassifier': KNeighborsClassifier(),

}

# Fonction d'application des modèles avec recherche sur grille
def train_test_eval_grid(models, param_grids, X_train, y_train, X_test, y_test):
    for name, model in models.items():
        grid_search = GridSearchCV(estimator=model, param_grid=param_grids[name], cv=5)
        grid_search.fit(X_train, y_train)
        best_model = grid_search.best_estimator_
        print(f"Meilleurs paramètres pour {name}: {grid_search.best_params_}")
        accu(y_test, best_model.predict(X_test))
        print('-' * 30)

# Exécution de la recherche sur grille pour chaque modèle
param_grids = {

    'KNeighborsClassifier': param_grid_knn,
}

train_test_eval_grid(models, param_grids, X_train, y_train, X_test, y_test)

param_grid_decision_tree = {'max_depth': [1, 3, 5, 7], 'criterion': ['gini', 'entropy']}


# Initialiser les modèles avec leurs paramètres par défaut
models = {

    'DecisionTreeClassifier': DecisionTreeClassifier(random_state=42)

}

# Fonction d'application des modèles avec recherche sur grille
def train_test_eval_grid(models, param_grids, X_train, y_train, X_test, y_test):
    for name, model in models.items():
        grid_search = GridSearchCV(estimator=model, param_grid=param_grids[name], cv=5)
        grid_search.fit(X_train, y_train)
        best_model = grid_search.best_estimator_
        print(f"Meilleurs paramètres pour {name}: {grid_search.best_params_}")
        accu(y_test, best_model.predict(X_test))
        print('-' * 30)

# Exécution de la recherche sur grille pour chaque modèle
param_grids = {

    'DecisionTreeClassifier': param_grid_decision_tree
}

train_test_eval_grid(models, param_grids, X_train, y_train, X_test, y_test)

#Résultats


# Entraînement des modèles avec les meilleurs hyperparamètres
best_models = {
    'Régression Logistique': LogisticRegression(C=1, random_state=42),
    'KNN': KNeighborsClassifier(n_neighbors=9),
    'Arbre de Décision': DecisionTreeClassifier(max_depth=1, criterion='gini', random_state=42)
}

for name, model in best_models.items():
    model.fit(X_train, y_train)

# Comparaison des précisions des modèles
accuracies = [accuracy_score(y_test, model.predict(X_test)) for model in best_models.values()]
models_names = list(best_models.keys())

plt.figure(figsize=(8, 6))
plt.bar(models_names, accuracies)
plt.xlabel('Modèle')
plt.ylabel('Précision (Accuracy)')
plt.title('Comparaison des précisions des modèles')
plt.ylim(0.55, 0.9)
plt.show()

#courbe

best_models = {
    'Régression Logistique': LogisticRegression(C=0.1, random_state=42),
    'KNN': KNeighborsClassifier(n_neighbors=5),
    'Arbre de Décision': DecisionTreeClassifier(max_depth=5, criterion='gini', random_state=42)
}

for name, model in best_models.items():
    model.fit(X_train, y_train)



# Courbe ROC des modèles
plt.figure(figsize=(8, 6))
for name, model in best_models.items():
    y_score = model.predict_proba(X_test)[:,1]
    fpr, tpr, _ = roc_curve(y_test, y_score)
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], linestyle='--', color='grey', label='Aléatoire')
plt.xlabel('Taux de faux positifs')
plt.ylabel('Taux de vrais positifs')
plt.title('Courbe ROC des modèles')
plt.legend()
plt.show()
